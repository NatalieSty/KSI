start_training
0
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.6030794791495948
1
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.734901654477688
2
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.7679716027816839
3
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.7847229698673691
4
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.7952191663062226
5
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8008368420836413
6
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8033225966502884
7
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8053460076459635
8
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8072151442706902
9
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8076540792292457
10
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8103220248445774
11
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8098716821297584
12
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8076220169618158
13
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8078047691254004
14
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8064020954850035
15
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8075654989589108
[0.6030794791495948, 0.734901654477688, 0.7679716027816839, 0.7847229698673691, 0.7952191663062226, 0.8008368420836413, 0.8033225966502884, 0.8053460076459635, 0.8072151442706902, 0.8076540792292457, 0.8103220248445774, 0.8098716821297584, 0.8076220169618158, 0.8078047691254004, 0.8064020954850035, 0.8075654989589108] 10
start_training
0
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8136138939609412
1
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8137964543796433
2
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8154447155085928
3
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8151216285201242
4
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.816301853702514
5
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8158554779206737
6
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8150330462244546
7
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8146224158881056
8
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.8127389306521088
9
XXXXXXXXXXXXXXXXXXXXXXXXXXXX
validation top- 10 0.813168480756464
[0.8136138939609412, 0.8137964543796433, 0.8154447155085928, 0.8151216285201242, 0.816301853702514, 0.8158554779206737, 0.8150330462244546, 0.8146224158881056, 0.8127389306521088, 0.813168480756464] 4
CAML alone:           
KSI_CAML.py:290: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  y_pred=(y_scores>0.5).astype(np.int)
top- 10 0.8083500764416498
macro AUC 0.8569716025006577
micro AUC 0.9778740004734764
macro F1 0.26467099488236867
micro F1 0.6590005140831732
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
KSI+CAML:           
KSI_CAML.py:290: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  y_pred=(y_scores>0.5).astype(np.int)
top- 10 0.8164831738930659
macro AUC 0.8900641410125089
micro AUC 0.9802566901595684
macro F1 0.3029546172306047
micro F1 0.663305527546063